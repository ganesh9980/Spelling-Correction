{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from utils.ipynb\n",
      "importing Jupyter notebook from model.ipynb\n",
      "Requirement already satisfied: unidecode in c:\\users\\ganes\\anaconda3\\lib\\site-packages (1.1.1)\n",
      "Requirement already satisfied: import_ipynb in c:\\users\\ganes\\anaconda3\\lib\\site-packages (0.1.3)\n",
      "['semm******************', 'Ynoder****************', 'roepened**************', 'unforeeen*************', \"ress'd****************\", \"jAdversity's**********\", 'grants****************', 'avWnging**************', 'forevIer**************', 'tunc******************']\n",
      "['\\tseem*****************', '\\tYonder***************', '\\treopened*************', '\\tunforeseen***********', \"\\tpress'd**************\", \"\\tAdversity's**********\", '\\tgrants***************', '\\tavenging*************', '\\tforever**************', '\\ttunic****************']\n",
      "['seem******************', 'Yonder****************', 'reopened**************', 'unforeseen************', \"press'd***************\", \"Adversity's***********\", 'grants****************', 'avenging**************', 'forever***************', 'tunic*****************']\n",
      "Size of training vocabulary = 33047\n",
      "Number of unique input characters: 55\n",
      "Number of unique target characters: 56\n",
      "Max sequence length in the training set: 22\n",
      "[\"iLAICE'S**************\", 'ADVENwURES************', 'IN********************', 'WONDERLAD*************', 'Lew s*****************', 'Carroll***************', 'dTHE******************', 'MILLENNIUM************', 'FULCRMU***************', 'EDITION***************']\n",
      "[\"\\tiALICE'S*************\", '\\tADVENTURES***********', '\\tIN*******************', '\\tWONDERLAND***********', '\\tLewis****************', '\\tCarroll**************', '\\tTHE******************', '\\tMILLENNIUM***********', '\\tFULCRUM**************', '\\tEDITION**************']\n",
      "[\"iALICE'S**************\", 'ADVENTURES************', 'IN********************', 'WONDERLAND************', 'Lewis*****************', 'Carroll***************', 'THE*******************', 'MILLENNIUM************', 'FULCRUM***************', 'EDITION***************']\n",
      "Number of non-unique validation tokens = 26763\n",
      "Max sequence length in the validation set: 16\n",
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_data (InputLayer)       [(None, None, 55)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_lstm_1 (LSTM)           (None, None, 512)    1163264     encoder_data[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder_data (InputLayer)       [(None, None, 56)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_lstm_2 (LSTM)           [(None, 512), (None, 2099200     encoder_lstm_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder_lstm (LSTM)             [(None, None, 512),  1165312     decoder_data[0][0]               \n",
      "                                                                 encoder_lstm_2[0][1]             \n",
      "                                                                 encoder_lstm_2[0][2]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder_softmax (Dense)         (None, None, 56)     28728       decoder_lstm[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 4,456,504\n",
      "Trainable params: 4,456,504\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Main Epoch 1/100\n",
      "Shuffling data.\n",
      "258/258 [==============================] - 660s 3s/step - loss: 1.1955 - accuracy: 0.6840 - truncated_acc: 0.5670 - truncated_loss: 1.6266 - val_loss: 0.7402 - val_accuracy: 0.8091 - val_truncated_acc: 0.7375 - val_truncated_loss: 1.0178\n",
      "-\n",
      "Input tokens:   ['a', 'hoSw', 'Caterpxllar', 'seemde', 'adn']\n",
      "Decoded tokens: ['serere', 'sereren', 'sereres', 'sereres', 'sereren']\n",
      "Target tokens:  ['a', 'how', 'Caterpillar', 'seemed', 'and']\n",
      "-\n",
      "Saving full model to checkpoints\\seq2seq_epoch_1.h5\n",
      "Main Epoch 2/100\n",
      "Shuffling data.\n",
      "258/258 [==============================] - 634s 2s/step - loss: 0.9501 - accuracy: 0.7206 - truncated_acc: 0.6159 - truncated_loss: 1.3062 - val_loss: 0.5229 - val_accuracy: 0.8496 - val_truncated_acc: 0.7932 - val_truncated_loss: 0.7190\n",
      "-\n",
      "Input tokens:   ['at', 'it', \"threre's\", 'hereelf', 'other']\n",
      "Decoded tokens: ['an', 'se', 'sorested', 'arented', 'sonte']\n",
      "Target tokens:  ['at', 'it', \"there's\", 'herself', 'other']\n",
      "-\n",
      "Saving full model to checkpoints\\seq2seq_epoch_2.h5\n",
      "Main Epoch 3/100\n",
      "Shuffling data.\n",
      "258/258 [==============================] - 665s 3s/step - loss: 0.7414 - accuracy: 0.7797 - truncated_acc: 0.6971 - truncated_loss: 1.0193 - val_loss: 0.3136 - val_accuracy: 0.9211 - val_truncated_acc: 0.8915 - val_truncated_loss: 0.4312\n",
      "-\n",
      "Input tokens:   ['voice', 'TEY', 'slates', 'rhe', 'alarXm']\n",
      "Decoded tokens: ['conie', 'SERE', 'saless', 'rer', 'amara']\n",
      "Target tokens:  ['voice', 'THEY', 'slates', 'She', 'alarm']\n",
      "-\n",
      "Saving full model to checkpoints\\seq2seq_epoch_3.h5\n",
      "Main Epoch 4/100\n",
      "Shuffling data.\n",
      "258/258 [==============================] - 628s 2s/step - loss: 0.4287 - accuracy: 0.8762 - truncated_acc: 0.8299 - truncated_loss: 0.5894 - val_loss: 0.1902 - val_accuracy: 0.9533 - val_truncated_acc: 0.9358 - val_truncated_loss: 0.2615\n",
      "-\n",
      "Input tokens:   ['There', 'of', 'Dormose', 'enougah', 'Oill']\n",
      "Decoded tokens: ['There', 'oo', 'Gormose', 'enough', 'Hill']\n",
      "Target tokens:  ['There', 'of', 'Dormouse', 'enough', 'till']\n",
      "-\n",
      "Saving full model to checkpoints\\seq2seq_epoch_4.h5\n",
      "Main Epoch 5/100\n",
      "Shuffling data.\n",
      "258/258 [==============================] - 617s 2s/step - loss: 0.3021 - accuracy: 0.9141 - truncated_acc: 0.8819 - truncated_loss: 0.4154 - val_loss: 0.1629 - val_accuracy: 0.9610 - val_truncated_acc: 0.9464 - val_truncated_loss: 0.2239\n",
      "-\n",
      "Input tokens:   ['to', 'speak', 'nad', 'tnook', 'Ahteling']\n",
      "Decoded tokens: ['to', 'speak', 'nad', 'toook', 'Ahteling']\n",
      "Target tokens:  ['to', 'speak', 'and', 'took', 'Atheling']\n",
      "-\n",
      "Saving full model to checkpoints\\seq2seq_epoch_5.h5\n",
      "Main Epoch 6/100\n",
      "Shuffling data.\n",
      "258/258 [==============================] - 629s 2s/step - loss: 0.2520 - accuracy: 0.9289 - truncated_acc: 0.9023 - truncated_loss: 0.3464 - val_loss: 0.1458 - val_accuracy: 0.9657 - val_truncated_acc: 0.9528 - val_truncated_loss: 0.2004\n",
      "-\n",
      "Input tokens:   ['fastre', 'rBosetree', 'masteF', 'liittle', 'For']\n",
      "Decoded tokens: ['faster', 'Bossere', 'masted', 'lititle', 'For']\n",
      "Target tokens:  ['faster', 'rosetree', 'master', 'little', 'For']\n",
      "-\n",
      "Saving full model to checkpoints\\seq2seq_epoch_6.h5\n",
      "Main Epoch 7/100\n",
      "Shuffling data.\n",
      "258/258 [==============================] - 620s 2s/step - loss: 0.2264 - accuracy: 0.9360 - truncated_acc: 0.9121 - truncated_loss: 0.3112 - val_loss: 0.1362 - val_accuracy: 0.9674 - val_truncated_acc: 0.9551 - val_truncated_loss: 0.1872\n",
      "-\n",
      "Input tokens:   ['ahbout', 'said', 'olver', 'the', \"n'\"]\n",
      "Decoded tokens: ['about', 'said', 'olver', 'the', \"n'\"]\n",
      "Target tokens:  ['about', 'said', 'over', 'the', \"on'\"]\n",
      "-\n",
      "Saving full model to checkpoints\\seq2seq_epoch_7.h5\n",
      "Main Epoch 8/100\n",
      "Shuffling data.\n",
      "258/258 [==============================] - 624s 2s/step - loss: 0.2108 - accuracy: 0.9410 - truncated_acc: 0.9189 - truncated_loss: 0.2898 - val_loss: 0.1327 - val_accuracy: 0.9686 - val_truncated_acc: 0.9568 - val_truncated_loss: 0.1825\n",
      "-\n",
      "Input tokens:   ['sDe', 'tLe', 'Alic', 'lice', 'sid']\n",
      "Decoded tokens: ['see', 'te', 'Alic', 'lice', 'sid']\n",
      "Target tokens:  ['she', 'the', 'Alice', 'Alice', 'said']\n",
      "-\n",
      "Saving full model to checkpoints\\seq2seq_epoch_8.h5\n",
      "Main Epoch 9/100\n",
      "Shuffling data.\n",
      "258/258 [==============================] - 582s 2s/step - loss: 0.1955 - accuracy: 0.9454 - truncated_acc: 0.9250 - truncated_loss: 0.2688 - val_loss: 0.1260 - val_accuracy: 0.9700 - val_truncated_acc: 0.9588 - val_truncated_loss: 0.1732\n",
      "-\n",
      "Input tokens:   ['lReft', 'remark', 'cOome', 'in', 'Loy']\n",
      "Decoded tokens: ['left', 'remark', 'come', 'in', 'Loy']\n",
      "Target tokens:  ['left', 'remark', 'come', 'in', 'Lory']\n",
      "-\n",
      "Saving full model to checkpoints\\seq2seq_epoch_9.h5\n",
      "Main Epoch 10/100\n",
      "Shuffling data.\n",
      "258/258 [==============================] - 574s 2s/step - loss: 0.1847 - accuracy: 0.9489 - truncated_acc: 0.9298 - truncated_loss: 0.2539 - val_loss: 0.1194 - val_accuracy: 0.9710 - val_truncated_acc: 0.9602 - val_truncated_loss: 0.1642\n",
      "-\n",
      "Input tokens:   ['teh', \"U'we're\", 'go', 'thje', 'on']\n",
      "Decoded tokens: ['tee', \"''wered\", 'go', 'the', 'on']\n",
      "Target tokens:  ['the', \"'we're\", 'go', 'the', 'on']\n",
      "-\n",
      "Saving full model to checkpoints\\seq2seq_epoch_10.h5\n",
      "Main Epoch 11/100\n",
      "Shuffling data.\n",
      "258/258 [==============================] - 636s 2s/step - loss: 0.1790 - accuracy: 0.9505 - truncated_acc: 0.9320 - truncated_loss: 0.2461 - val_loss: 0.1161 - val_accuracy: 0.9711 - val_truncated_acc: 0.9603 - val_truncated_loss: 0.1596\n",
      "-\n",
      "Input tokens:   ['it', 'a', 'getting', \"'I\", 'teh']\n",
      "Decoded tokens: ['it', 'a', 'getting', \"'I\", 'teth']\n",
      "Target tokens:  ['it', 'a', 'getting', \"'I\", 'the']\n",
      "-\n",
      "Saving full model to checkpoints\\seq2seq_epoch_11.h5\n",
      "Main Epoch 12/100\n",
      "Shuffling data.\n",
      "258/258 [==============================] - 613s 2s/step - loss: 0.1699 - accuracy: 0.9531 - truncated_acc: 0.9356 - truncated_loss: 0.2336 - val_loss: 0.1178 - val_accuracy: 0.9717 - val_truncated_acc: 0.9611 - val_truncated_loss: 0.1620\n",
      "-\n",
      "Input tokens:   ['trgouble', 'oging', 'ainting', 'it', \"I'\"]\n",
      "Decoded tokens: ['troguble', 'oging', 'ainting', 'it', \"I'\"]\n",
      "Target tokens:  ['trouble', 'going', 'painting', 'it', \"I'm\"]\n",
      "-\n",
      "Saving full model to checkpoints\\seq2seq_epoch_12.h5\n",
      "Main Epoch 13/100\n",
      "Shuffling data.\n",
      "258/258 [==============================] - 629s 2s/step - loss: 0.1657 - accuracy: 0.9545 - truncated_acc: 0.9375 - truncated_loss: 0.2278 - val_loss: 0.1138 - val_accuracy: 0.9730 - val_truncated_acc: 0.9628 - val_truncated_loss: 0.1565\n",
      "-\n",
      "Input tokens:   ['rvad', 'nad', 'Our', 'CVt', \"'I\"]\n",
      "Decoded tokens: ['rave', 'nad', 'Our', 'Cit', \"'I\"]\n",
      "Target tokens:  ['read', 'and', 'Our', 'Cat', \"'I\"]\n",
      "-\n",
      "Saving full model to checkpoints\\seq2seq_epoch_13.h5\n",
      "Main Epoch 14/100\n",
      "Shuffling data.\n",
      "258/258 [==============================] - 621s 2s/step - loss: 0.1597 - accuracy: 0.9560 - truncated_acc: 0.9395 - truncated_loss: 0.2196 - val_loss: 0.1096 - val_accuracy: 0.9737 - val_truncated_acc: 0.9639 - val_truncated_loss: 0.1506\n",
      "-\n",
      "Input tokens:   ['beaders', 'she', 'wre', 'writig', 'ohe']\n",
      "Decoded tokens: ['beaders', 'she', 'wre', 'writing', 'hoe']\n",
      "Target tokens:  ['leaders', 'she', 'were', 'writing', 'the']\n",
      "-\n",
      "Saving full model to checkpoints\\seq2seq_epoch_14.h5\n",
      "Main Epoch 15/100\n",
      "Shuffling data.\n",
      "258/258 [==============================] - 603s 2s/step - loss: 0.1546 - accuracy: 0.9579 - truncated_acc: 0.9421 - truncated_loss: 0.2126 - val_loss: 0.1084 - val_accuracy: 0.9742 - val_truncated_acc: 0.9646 - val_truncated_loss: 0.1490\n",
      "-\n",
      "Input tokens:   ['grni', \"now'\", 'moJuth', \"'But\", 'At']\n",
      "Decoded tokens: ['grin', \"now'\", 'mouth', \"'But\", 'At']\n",
      "Target tokens:  ['grin', \"now'\", 'mouth', \"'But\", 'At']\n",
      "-\n",
      "Saving full model to checkpoints\\seq2seq_epoch_15.h5\n",
      "Main Epoch 16/100\n",
      "Shuffling data.\n",
      "258/258 [==============================] - 598s 2s/step - loss: 0.1499 - accuracy: 0.9590 - truncated_acc: 0.9436 - truncated_loss: 0.2061 - val_loss: 0.1053 - val_accuracy: 0.9742 - val_truncated_acc: 0.9645 - val_truncated_loss: 0.1448\n",
      "-\n",
      "Input tokens:   ['rought', \"didn'v\", 'scuh', 'shriek', 'BVt']\n",
      "Decoded tokens: ['rought', \"didn'\", 'scuch', 'shriek', 'Bit']\n",
      "Target tokens:  ['brought', \"didn't\", 'such', 'shriek', 'But']\n",
      "-\n",
      "Saving full model to checkpoints\\seq2seq_epoch_16.h5\n",
      "Main Epoch 17/100\n",
      "Shuffling data.\n",
      "258/258 [==============================] - 598s 2s/step - loss: 0.1455 - accuracy: 0.9603 - truncated_acc: 0.9454 - truncated_loss: 0.2000 - val_loss: 0.1051 - val_accuracy: 0.9749 - val_truncated_acc: 0.9654 - val_truncated_loss: 0.1445\n",
      "-\n",
      "Input tokens:   ['ont', 'otu', 'ugl', 'so', 'Cnd']\n",
      "Decoded tokens: ['ont', 'out', 'gull', 'so', 'Cond']\n",
      "Target tokens:  ['not', 'out', 'ugly', 'so', 'and']\n",
      "-\n",
      "Saving full model to checkpoints\\seq2seq_epoch_17.h5\n",
      "Main Epoch 18/100\n",
      "Shuffling data.\n",
      "258/258 [==============================] - 607s 2s/step - loss: 0.1415 - accuracy: 0.9614 - truncated_acc: 0.9469 - truncated_loss: 0.1945 - val_loss: 0.1014 - val_accuracy: 0.9755 - val_truncated_acc: 0.9664 - val_truncated_loss: 0.1394\n",
      "-\n",
      "Input tokens:   ['niew', 'shs', 'TO', 'foDnd', 'temperedr']\n",
      "Decoded tokens: ['niew', 'shes', 'TO', 'found', 'temperer']\n",
      "Target tokens:  ['new', 'she', 'TO', 'found', \"tempered'\"]\n",
      "-\n",
      "Saving full model to checkpoints\\seq2seq_epoch_18.h5\n",
      "Main Epoch 19/100\n",
      "Shuffling data.\n",
      "258/258 [==============================] - 576s 2s/step - loss: 0.1382 - accuracy: 0.9623 - truncated_acc: 0.9481 - truncated_loss: 0.1900 - val_loss: 0.1016 - val_accuracy: 0.9748 - val_truncated_acc: 0.9654 - val_truncated_loss: 0.1397\n",
      "-\n",
      "Input tokens:   ['Bids', 'sad', 'a', 'qiute', 'iztself']\n",
      "Decoded tokens: ['Bids', 'sad', 'a', 'quite', 'intelf']\n",
      "Target tokens:  ['Birds', 'said', 'a', 'quite', 'itself']\n",
      "-\n",
      "Saving full model to checkpoints\\seq2seq_epoch_19.h5\n",
      "Main Epoch 20/100\n",
      "Shuffling data.\n",
      "258/258 [==============================] - 562s 2s/step - loss: 0.1340 - accuracy: 0.9634 - truncated_acc: 0.9497 - truncated_loss: 0.1843 - val_loss: 0.1022 - val_accuracy: 0.9744 - val_truncated_acc: 0.9648 - val_truncated_loss: 0.1406\n",
      "-\n",
      "Input tokens:   ['nd', 'sore', 'bnk', 'a', 'an']\n",
      "Decoded tokens: ['ned', 'sore', 'bank', 'a', 'an']\n",
      "Target tokens:  ['and', 'shore', 'bank', 'a', 'an']\n",
      "-\n",
      "Saving full model to checkpoints\\seq2seq_epoch_20.h5\n",
      "Main Epoch 21/100\n",
      "Shuffling data.\n",
      "258/258 [==============================] - 563s 2s/step - loss: 0.1304 - accuracy: 0.9644 - truncated_acc: 0.9511 - truncated_loss: 0.1793 - val_loss: 0.0994 - val_accuracy: 0.9759 - val_truncated_acc: 0.9668 - val_truncated_loss: 0.1367\n",
      "-\n",
      "Input tokens:   ['I', 'fozr', 'teh', 'seemed', 'unhappy']\n",
      "Decoded tokens: ['I', 'fore', 'the', 'seemed', 'unhappy']\n",
      "Target tokens:  ['I', 'for', 'the', 'seemed', 'unhappy']\n",
      "-\n",
      "Saving full model to checkpoints\\seq2seq_epoch_21.h5\n",
      "Main Epoch 22/100\n",
      "Shuffling data.\n",
      "258/258 [==============================] - 601s 2s/step - loss: 0.1265 - accuracy: 0.9654 - truncated_acc: 0.9525 - truncated_loss: 0.1739 - val_loss: 0.0972 - val_accuracy: 0.9759 - val_truncated_acc: 0.9669 - val_truncated_loss: 0.1336\n",
      "-\n",
      "Input tokens:   ['be', 'In', 'waI', 'HaWe', 'sh ']\n",
      "Decoded tokens: ['be', 'In', 'wai', 'Hate', 'sha']\n",
      "Target tokens:  ['be', 'In', 'way', 'Hare', 'she']\n",
      "-\n",
      "Saving full model to checkpoints\\seq2seq_epoch_22.h5\n",
      "Main Epoch 23/100\n",
      "Shuffling data.\n",
      "258/258 [==============================] - 592s 2s/step - loss: 0.1260 - accuracy: 0.9655 - truncated_acc: 0.9525 - truncated_loss: 0.1733 - val_loss: 0.0988 - val_accuracy: 0.9753 - val_truncated_acc: 0.9661 - val_truncated_loss: 0.1358\n",
      "-\n",
      "Input tokens:   ['teh', 'teh', 'White', 'ws', 'righ']\n",
      "Decoded tokens: ['tee', 'tee', 'White', 'ws', 'righ']\n",
      "Target tokens:  ['the', 'the', 'White', 'was', 'right']\n",
      "-\n",
      "Saving full model to checkpoints\\seq2seq_epoch_23.h5\n",
      "Main Epoch 24/100\n",
      "Shuffling data.\n",
      "258/258 [==============================] - 574s 2s/step - loss: 0.1222 - accuracy: 0.9666 - truncated_acc: 0.9541 - truncated_loss: 0.1680 - val_loss: 0.0960 - val_accuracy: 0.9761 - val_truncated_acc: 0.9671 - val_truncated_loss: 0.1320\n",
      "-\n",
      "Input tokens:   ['askinqg', 'questinos', 'thSe', 'and', 'markmd']\n",
      "Decoded tokens: ['asking', 'questions', 'the', 'and', 'marked']\n",
      "Target tokens:  ['asking', 'questions', 'the', 'and', 'marked']\n",
      "-\n",
      "Saving full model to checkpoints\\seq2seq_epoch_24.h5\n",
      "Main Epoch 25/100\n",
      "Shuffling data.\n",
      "258/258 [==============================] - 577s 2s/step - loss: 0.1208 - accuracy: 0.9669 - truncated_acc: 0.9544 - truncated_loss: 0.1661 - val_loss: 0.0919 - val_accuracy: 0.9775 - val_truncated_acc: 0.9690 - val_truncated_loss: 0.1264\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input tokens:   ['snathc', 'stUill', 'of', 'me', 'satid']\n",
      "Decoded tokens: ['snatch', 'still', 'of', 'me', 'satid']\n",
      "Target tokens:  ['snatch', 'still', 'of', 'me', 'said']\n",
      "-\n",
      "Saving full model to checkpoints\\seq2seq_epoch_25.h5\n",
      "Main Epoch 26/100\n",
      "Shuffling data.\n",
      "258/258 [==============================] - 593s 2s/step - loss: 0.1176 - accuracy: 0.9678 - truncated_acc: 0.9557 - truncated_loss: 0.1618 - val_loss: 0.0949 - val_accuracy: 0.9760 - val_truncated_acc: 0.9670 - val_truncated_loss: 0.1304\n",
      "-\n",
      "Input tokens:   ['liRe', 'as', 'to', 'fijnd', 'tPe']\n",
      "Decoded tokens: ['lime', 'as', 'to', 'fined', 'tee']\n",
      "Target tokens:  ['like', 'as', 'to', 'find', 'the']\n",
      "-\n",
      "Saving full model to checkpoints\\seq2seq_epoch_26.h5\n",
      "Main Epoch 27/100\n",
      "Shuffling data.\n",
      "258/258 [==============================] - 575s 2s/step - loss: 0.1151 - accuracy: 0.9685 - truncated_acc: 0.9566 - truncated_loss: 0.1582 - val_loss: 0.0908 - val_accuracy: 0.9777 - val_truncated_acc: 0.9693 - val_truncated_loss: 0.1248\n",
      "-\n",
      "Input tokens:   ['finsihed', 'agani', 'DinHah', 'HAVE', 'a']\n",
      "Decoded tokens: ['finished', 'agani', 'Dinah', 'HAVE', 'a']\n",
      "Target tokens:  ['finished', 'again', 'Dinah', 'HAVE', 'a']\n",
      "-\n",
      "Saving full model to checkpoints\\seq2seq_epoch_27.h5\n",
      "Main Epoch 28/100\n",
      "Shuffling data.\n",
      "258/258 [==============================] - 567s 2s/step - loss: 0.1124 - accuracy: 0.9692 - truncated_acc: 0.9576 - truncated_loss: 0.1546 - val_loss: 0.0883 - val_accuracy: 0.9781 - val_truncated_acc: 0.9699 - val_truncated_loss: 0.1214\n",
      "-\n",
      "Input tokens:   [\"'Who'\", 'cold', \"'juy\", 'Last', 'of']\n",
      "Decoded tokens: [\"'Who'\", 'cold', \"'juy\", 'Last', 'of']\n",
      "Target tokens:  [\"'Who's\", 'could', \"'jury\", 'Last', 'of']\n",
      "-\n",
      "Saving full model to checkpoints\\seq2seq_epoch_28.h5\n",
      "Main Epoch 29/100\n",
      "Shuffling data.\n",
      "258/258 [==============================] - 563s 2s/step - loss: 0.1099 - accuracy: 0.9701 - truncated_acc: 0.9589 - truncated_loss: 0.1512 - val_loss: 0.0908 - val_accuracy: 0.9780 - val_truncated_acc: 0.9697 - val_truncated_loss: 0.1249\n",
      "-\n",
      "Input tokens:   ['otu', \"head'\", 'in', 'loudlny', 'Quejen']\n",
      "Decoded tokens: ['out', \"head'\", 'in', 'loundly', 'Queen']\n",
      "Target tokens:  ['out', \"head'\", 'in', 'loudly', 'Queen']\n",
      "-\n",
      "Saving full model to checkpoints\\seq2seq_epoch_29.h5\n",
      "Main Epoch 30/100\n",
      "Shuffling data.\n",
      "258/258 [==============================] - 578s 2s/step - loss: 0.1080 - accuracy: 0.9706 - truncated_acc: 0.9596 - truncated_loss: 0.1485 - val_loss: 0.0870 - val_accuracy: 0.9784 - val_truncated_acc: 0.9703 - val_truncated_loss: 0.1197\n",
      "-\n",
      "Input tokens:   ['ltivery', 'else', 'repled', 'kinV', 'atnd']\n",
      "Decoded tokens: ['livery', 'else', 'repled', 'king', 'tand']\n",
      "Target tokens:  ['livery', 'else', 'replied', 'kind', 'and']\n",
      "-\n",
      "Saving full model to checkpoints\\seq2seq_epoch_30.h5\n",
      "Main Epoch 31/100\n",
      "Shuffling data.\n",
      "258/258 [==============================] - 643s 2s/step - loss: 0.1063 - accuracy: 0.9709 - truncated_acc: 0.9600 - truncated_loss: 0.1462 - val_loss: 0.0884 - val_accuracy: 0.9784 - val_truncated_acc: 0.9703 - val_truncated_loss: 0.1215\n",
      "-\n",
      "Input tokens:   ['udner', 'curious', 'whicDh', 'which', 'in']\n",
      "Decoded tokens: ['dunder', 'curious', 'which', 'which', 'in']\n",
      "Target tokens:  ['under', 'curious', 'which', 'which', 'in']\n",
      "-\n",
      "Saving full model to checkpoints\\seq2seq_epoch_31.h5\n",
      "Main Epoch 32/100\n",
      "Shuffling data.\n",
      "258/258 [==============================] - 593s 2s/step - loss: 0.1044 - accuracy: 0.9714 - truncated_acc: 0.9607 - truncated_loss: 0.1436 - val_loss: 0.0855 - val_accuracy: 0.9789 - val_truncated_acc: 0.9709 - val_truncated_loss: 0.1176\n",
      "-\n",
      "Input tokens:   ['counrty', \"'AEd\", 'at', 'ubt', 'Vack']\n",
      "Decoded tokens: ['country', \"'Aid\", 'at', 'but', 'Vack']\n",
      "Target tokens:  ['country', \"'And\", 'at', 'but', 'back']\n",
      "-\n",
      "Saving full model to checkpoints\\seq2seq_epoch_32.h5\n",
      "Main Epoch 33/100\n",
      "Shuffling data.\n",
      "258/258 [==============================] - 568s 2s/step - loss: 0.1034 - accuracy: 0.9716 - truncated_acc: 0.9609 - truncated_loss: 0.1422 - val_loss: 0.0858 - val_accuracy: 0.9788 - val_truncated_acc: 0.9709 - val_truncated_loss: 0.1179\n",
      "-\n",
      "Input tokens:   ['botle', 'ekverything', 'wiZh', 'ws', 'oon']\n",
      "Decoded tokens: ['bottle', 'everything', 'wish', 'wis', 'oon']\n",
      "Target tokens:  ['bottle', 'everything', 'with', 'was', 'soon']\n",
      "-\n",
      "Saving full model to checkpoints\\seq2seq_epoch_33.h5\n",
      "Main Epoch 34/100\n",
      "Shuffling data.\n",
      "258/258 [==============================] - 565s 2s/step - loss: 0.1004 - accuracy: 0.9722 - truncated_acc: 0.9618 - truncated_loss: 0.1381 - val_loss: 0.0832 - val_accuracy: 0.9790 - val_truncated_acc: 0.9711 - val_truncated_loss: 0.1144\n",
      "-\n",
      "Input tokens:   ['instead', 'cold', 'choruBs', 'replied', \"'Yes\"]\n",
      "Decoded tokens: ['instead', 'cold', 'chours', 'replied', \"'Yes\"]\n",
      "Target tokens:  ['instead', 'cold', 'chorus', 'replied', \"'Yes\"]\n",
      "-\n",
      "Saving full model to checkpoints\\seq2seq_epoch_34.h5\n",
      "Main Epoch 35/100\n",
      "Shuffling data.\n",
      "258/258 [==============================] - 562s 2s/step - loss: 0.0988 - accuracy: 0.9728 - truncated_acc: 0.9627 - truncated_loss: 0.1358 - val_loss: 0.0852 - val_accuracy: 0.9790 - val_truncated_acc: 0.9711 - val_truncated_loss: 0.1171\n",
      "-\n",
      "Input tokens:   ['esemed', 'nhe', 'zrue', 'Aice', 'morMe']\n",
      "Decoded tokens: ['seemed', 'neh', 'rure', 'Asce', 'more']\n",
      "Target tokens:  ['seemed', 'the', 'true', 'Alice', 'more']\n",
      "-\n",
      "Saving full model to checkpoints\\seq2seq_epoch_35.h5\n",
      "Main Epoch 36/100\n",
      "Shuffling data.\n",
      "258/258 [==============================] - 594s 2s/step - loss: 0.0992 - accuracy: 0.9727 - truncated_acc: 0.9624 - truncated_loss: 0.1365 - val_loss: 0.0876 - val_accuracy: 0.9779 - val_truncated_acc: 0.9696 - val_truncated_loss: 0.1205\n",
      "-\n",
      "Input tokens:   ['rdopped', 'lke', 'muc', 'a', 'an']\n",
      "Decoded tokens: ['dropped', 'lake', 'muck', 'a', 'an']\n",
      "Target tokens:  ['dropped', 'like', 'much', 'a', 'and']\n",
      "-\n",
      "Saving full model to checkpoints\\seq2seq_epoch_36.h5\n",
      "Main Epoch 37/100\n",
      "Shuffling data.\n",
      "258/258 [==============================] - 609s 2s/step - loss: 0.0978 - accuracy: 0.9730 - truncated_acc: 0.9628 - truncated_loss: 0.1345 - val_loss: 0.0826 - val_accuracy: 0.9796 - val_truncated_acc: 0.9719 - val_truncated_loss: 0.1136\n",
      "-\n",
      "Input tokens:   ['wou', 'abou', 'called', 'her', 'tomorrou']\n",
      "Decoded tokens: ['wour', 'abour', 'called', 'her', 'tomorrous']\n",
      "Target tokens:  ['you', 'about', 'called', 'her', 'tomorrow']\n",
      "-\n",
      "Saving full model to checkpoints\\seq2seq_epoch_37.h5\n",
      "Main Epoch 38/100\n",
      "Shuffling data.\n",
      "258/258 [==============================] - 577s 2s/step - loss: 0.0950 - accuracy: 0.9741 - truncated_acc: 0.9644 - truncated_loss: 0.1306 - val_loss: 0.0821 - val_accuracy: 0.9795 - val_truncated_acc: 0.9718 - val_truncated_loss: 0.1129\n",
      "-\n",
      "Input tokens:   ['a', 'sid', 'I', 'of', 'ozder']\n",
      "Decoded tokens: ['a', 'sid', 'I', 'of', 'odder']\n",
      "Target tokens:  ['a', 'said', 'I', 'of', 'older']\n",
      "-\n",
      "Saving full model to checkpoints\\seq2seq_epoch_38.h5\n",
      "Main Epoch 39/100\n",
      "Shuffling data.\n",
      "258/258 [==============================] - 561s 2s/step - loss: 0.0941 - accuracy: 0.9741 - truncated_acc: 0.9644 - truncated_loss: 0.1294 - val_loss: 0.0841 - val_accuracy: 0.9789 - val_truncated_acc: 0.9710 - val_truncated_loss: 0.1157\n",
      "-\n",
      "Input tokens:   ['Dthe', 'hYrs', 'wKhen', 'anU', 'doCwn']\n",
      "Decoded tokens: ['Dathe', 'hers', 'when', \"an'\", 'down']\n",
      "Target tokens:  ['the', 'hers', 'when', 'and', 'down']\n",
      "-\n",
      "Saving full model to checkpoints\\seq2seq_epoch_39.h5\n",
      "Main Epoch 40/100\n",
      "Shuffling data.\n",
      "258/258 [==============================] - 561s 2s/step - loss: 0.0916 - accuracy: 0.9747 - truncated_acc: 0.9653 - truncated_loss: 0.1259 - val_loss: 0.0789 - val_accuracy: 0.9796 - val_truncated_acc: 0.9719 - val_truncated_loss: 0.1085\n",
      "-\n",
      "Input tokens:   ['tkem', 'lagre', 'notioG', 'thnigs', 'on']\n",
      "Decoded tokens: ['tame', 'lager', 'notion', 'things', 'on']\n",
      "Target tokens:  ['them', 'large', 'notion', 'things', 'on']\n",
      "-\n",
      "Saving full model to checkpoints\\seq2seq_epoch_40.h5\n",
      "Main Epoch 41/100\n",
      "Shuffling data.\n",
      "258/258 [==============================] - 559s 2s/step - loss: 0.0919 - accuracy: 0.9746 - truncated_acc: 0.9650 - truncated_loss: 0.1264 - val_loss: 0.0783 - val_accuracy: 0.9800 - val_truncated_acc: 0.9725 - val_truncated_loss: 0.1077\n",
      "-\n",
      "Input tokens:   ['lookded', 'aut', 'bega', 'anothezr', 'nea']\n",
      "Decoded tokens: ['looked', 'aut', 'bega', 'another', 'nea']\n",
      "Target tokens:  ['looked', 'but', 'began', 'another', 'near']\n",
      "-\n",
      "Saving full model to checkpoints\\seq2seq_epoch_41.h5\n",
      "Main Epoch 42/100\n",
      "Shuffling data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "258/258 [==============================] - 560s 2s/step - loss: 0.0894 - accuracy: 0.9754 - truncated_acc: 0.9662 - truncated_loss: 0.1229 - val_loss: 0.0802 - val_accuracy: 0.9794 - val_truncated_acc: 0.9717 - val_truncated_loss: 0.1102\n",
      "-\n",
      "Input tokens:   ['sZe', 'antd', \"'I\", 'saif', 'gnder']\n",
      "Decoded tokens: ['se', 'anted', \"'I\", 'sail', 'gonder']\n",
      "Target tokens:  ['see', 'and', \"'I\", 'said', 'under']\n",
      "-\n",
      "Saving full model to checkpoints\\seq2seq_epoch_42.h5\n",
      "Main Epoch 43/100\n",
      "Shuffling data.\n",
      "258/258 [==============================] - 561s 2s/step - loss: 0.0875 - accuracy: 0.9758 - truncated_acc: 0.9667 - truncated_loss: 0.1203 - val_loss: 0.0807 - val_accuracy: 0.9788 - val_truncated_acc: 0.9709 - val_truncated_loss: 0.1110\n",
      "-\n",
      "Input tokens:   ['frying', 'rst', 'a', 'cotent', 'anoqther']\n",
      "Decoded tokens: ['frying', 'rust', 'a', 'content', 'another']\n",
      "Target tokens:  ['frying', 'rest', 'a', 'content', 'another']\n",
      "-\n",
      "Saving full model to checkpoints\\seq2seq_epoch_43.h5\n",
      "Main Epoch 44/100\n",
      "Shuffling data.\n",
      "258/258 [==============================] - 563s 2s/step - loss: 0.0871 - accuracy: 0.9761 - truncated_acc: 0.9671 - truncated_loss: 0.1198 - val_loss: 0.0809 - val_accuracy: 0.9798 - val_truncated_acc: 0.9722 - val_truncated_loss: 0.1112\n",
      "-\n",
      "Input tokens:   ['skurried', 'the', 'aws', 'odwn', 'yuor']\n",
      "Decoded tokens: ['skurried', 'the', 'laws', 'down', 'your']\n",
      "Target tokens:  ['skurried', 'the', 'was', 'down', 'your']\n",
      "-\n",
      "Saving full model to checkpoints\\seq2seq_epoch_44.h5\n",
      "Main Epoch 45/100\n",
      "Shuffling data.\n",
      "258/258 [==============================] - 558s 2s/step - loss: 0.0860 - accuracy: 0.9762 - truncated_acc: 0.9672 - truncated_loss: 0.1182 - val_loss: 0.0787 - val_accuracy: 0.9803 - val_truncated_acc: 0.9729 - val_truncated_loss: 0.1082\n",
      "-\n",
      "Input tokens:   ['alwayx', 'teh', 'cuold', 'lXrge', 'up']\n",
      "Decoded tokens: ['alway', 'the', 'could', 'lorge', 'up']\n",
      "Target tokens:  ['always', 'the', 'could', 'large', 'up']\n",
      "-\n",
      "Saving full model to checkpoints\\seq2seq_epoch_45.h5\n",
      "Main Epoch 46/100\n",
      "Shuffling data.\n",
      "258/258 [==============================] - 561s 2s/step - loss: 0.0834 - accuracy: 0.9771 - truncated_acc: 0.9685 - truncated_loss: 0.1147 - val_loss: 0.0774 - val_accuracy: 0.9802 - val_truncated_acc: 0.9728 - val_truncated_loss: 0.1065\n",
      "-\n",
      "Input tokens:   ['shouteTd', 'dowJn', 'foKr', 'to', \"'tSuff\"]\n",
      "Decoded tokens: ['shouted', 'down', 'for', 'to', \"'Stuff\"]\n",
      "Target tokens:  ['shouted', 'down', 'for', 'to', \"'Stuff\"]\n",
      "-\n",
      "Saving full model to checkpoints\\seq2seq_epoch_46.h5\n",
      "Main Epoch 47/100\n",
      "Shuffling data.\n",
      "258/258 [==============================] - 560s 2s/step - loss: 0.0842 - accuracy: 0.9766 - truncated_acc: 0.9679 - truncated_loss: 0.1158 - val_loss: 0.0778 - val_accuracy: 0.9801 - val_truncated_acc: 0.9727 - val_truncated_loss: 0.1070\n",
      "-\n",
      "Input tokens:   ['tryig', 'thy', 'it', 'to', 'eer']\n",
      "Decoded tokens: ['trying', 'thy', 'it', 'to', 'ere']\n",
      "Target tokens:  ['trying', 'the', 'it', 'to', 'ever']\n",
      "-\n",
      "Saving full model to checkpoints\\seq2seq_epoch_47.h5\n",
      "Main Epoch 48/100\n",
      "Shuffling data.\n",
      "258/258 [==============================] - 563s 2s/step - loss: 0.0834 - accuracy: 0.9769 - truncated_acc: 0.9682 - truncated_loss: 0.1147 - val_loss: 0.0769 - val_accuracy: 0.9805 - val_truncated_acc: 0.9732 - val_truncated_loss: 0.1057\n",
      "-\n",
      "Input tokens:   ['nxt', 'whkn', 'theb', 'sOhe', 'thQugh']\n",
      "Decoded tokens: ['net', 'whin', 'theb', 'she', 'though']\n",
      "Target tokens:  ['next', 'when', 'them', 'she', 'though']\n",
      "-\n",
      "Saving full model to checkpoints\\seq2seq_epoch_48.h5\n",
      "Main Epoch 49/100\n",
      "Shuffling data.\n",
      "258/258 [==============================] - 560s 2s/step - loss: 0.0822 - accuracy: 0.9772 - truncated_acc: 0.9686 - truncated_loss: 0.1130 - val_loss: 0.0796 - val_accuracy: 0.9803 - val_truncated_acc: 0.9730 - val_truncated_loss: 0.1095\n",
      "-\n",
      "Input tokens:   ['updon', 'to', 'birds', 'a', \"i't\"]\n",
      "Decoded tokens: ['updon', 'to', 'birds', 'a', \"in't\"]\n",
      "Target tokens:  ['upon', 'to', 'birds', 'a', \"it'\"]\n",
      "-\n",
      "Saving full model to checkpoints\\seq2seq_epoch_49.h5\n",
      "Main Epoch 50/100\n",
      "Shuffling data.\n",
      "258/258 [==============================] - 564s 2s/step - loss: 0.0807 - accuracy: 0.9776 - truncated_acc: 0.9692 - truncated_loss: 0.1109 - val_loss: 0.0770 - val_accuracy: 0.9802 - val_truncated_acc: 0.9728 - val_truncated_loss: 0.1059\n",
      "-\n",
      "Input tokens:   ['heard', 'hse', 'many', 'sEid', 'fre']\n",
      "Decoded tokens: ['heard', 'hase', 'many', 'sid', 'fre']\n",
      "Target tokens:  ['heard', 'she', 'many', 'said', 'free']\n",
      "-\n",
      "Saving full model to checkpoints\\seq2seq_epoch_50.h5\n",
      "Main Epoch 51/100\n",
      "Shuffling data.\n",
      "258/258 [==============================] - 560s 2s/step - loss: 0.0802 - accuracy: 0.9778 - truncated_acc: 0.9694 - truncated_loss: 0.1103 - val_loss: 0.0791 - val_accuracy: 0.9798 - val_truncated_acc: 0.9722 - val_truncated_loss: 0.1088\n",
      "-\n",
      "Input tokens:   ['by', 'asid', 'kGck', 'in', 'other']\n",
      "Decoded tokens: ['by', 'asid', 'kick', 'in', 'other']\n",
      "Target tokens:  ['by', 'said', 'kick', 'in', 'other']\n",
      "-\n",
      "Saving full model to checkpoints\\seq2seq_epoch_51.h5\n",
      "Main Epoch 52/100\n",
      "Shuffling data.\n",
      "258/258 [==============================] - 559s 2s/step - loss: 0.0791 - accuracy: 0.9780 - truncated_acc: 0.9698 - truncated_loss: 0.1088 - val_loss: 0.0754 - val_accuracy: 0.9809 - val_truncated_acc: 0.9738 - val_truncated_loss: 0.1037\n",
      "-\n",
      "Input tokens:   ['alone', 'walk', 'entd', 'at', 'usch']\n",
      "Decoded tokens: ['alone', 'walk', 'ented', 'at', 'such']\n",
      "Target tokens:  ['alone', 'walk', 'end', 'at', 'such']\n",
      "-\n",
      "Saving full model to checkpoints\\seq2seq_epoch_52.h5\n",
      "Main Epoch 53/100\n",
      "Shuffling data.\n",
      "258/258 [==============================] - 561s 2s/step - loss: 0.0774 - accuracy: 0.9786 - truncated_acc: 0.9705 - truncated_loss: 0.1065 - val_loss: 0.0757 - val_accuracy: 0.9811 - val_truncated_acc: 0.9740 - val_truncated_loss: 0.1041\n",
      "-\n",
      "Input tokens:   ['hTe', \"'Hadn\", 'choes', 'Alice', 'rtwo']\n",
      "Decoded tokens: ['The', \"'Hand\", 'chose', 'Alice', 'tro']\n",
      "Target tokens:  ['The', \"'Hand\", 'chose', 'Alice', 'two']\n",
      "-\n",
      "Saving full model to checkpoints\\seq2seq_epoch_53.h5\n",
      "Main Epoch 54/100\n",
      "Shuffling data.\n",
      "258/258 [==============================] - 559s 2s/step - loss: 0.0775 - accuracy: 0.9785 - truncated_acc: 0.9705 - truncated_loss: 0.1066 - val_loss: 0.0756 - val_accuracy: 0.9812 - val_truncated_acc: 0.9742 - val_truncated_loss: 0.1039\n",
      "-\n",
      "Input tokens:   ['jst', 'a', 'Aliec', 'saik', 'you']\n",
      "Decoded tokens: ['jest', 'a', 'Alice', 'sail', 'you']\n",
      "Target tokens:  ['just', 'a', 'Alice', 'said', 'you']\n",
      "-\n",
      "Saving full model to checkpoints\\seq2seq_epoch_54.h5\n",
      "Main Epoch 55/100\n",
      "Shuffling data.\n",
      "258/258 [==============================] - 558s 2s/step - loss: 0.0782 - accuracy: 0.9782 - truncated_acc: 0.9701 - truncated_loss: 0.1075 - val_loss: 0.0744 - val_accuracy: 0.9816 - val_truncated_acc: 0.9746 - val_truncated_loss: 0.1023\n",
      "-\n",
      "Input tokens:   ['btu', 'whne', 'thing', \"ting'\", 'nto']\n",
      "Decoded tokens: ['but', 'whone', 'thing', \"ting'\", 'not']\n",
      "Target tokens:  ['but', 'when', 'thing', \"thing'\", 'not']\n",
      "-\n",
      "Saving full model to checkpoints\\seq2seq_epoch_55.h5\n",
      "Main Epoch 56/100\n",
      "Shuffling data.\n",
      "258/258 [==============================] - 561s 2s/step - loss: 0.0764 - accuracy: 0.9788 - truncated_acc: 0.9708 - truncated_loss: 0.1051 - val_loss: 0.0754 - val_accuracy: 0.9810 - val_truncated_acc: 0.9739 - val_truncated_loss: 0.1037\n",
      "-\n",
      "Input tokens:   ['Zheir', 'yoDr', 'th', 'Ihe', 'ogt']\n",
      "Decoded tokens: ['heir', 'your', 'th', 'Ihe', 'got']\n",
      "Target tokens:  ['their', 'your', 'the', 'the', 'got']\n",
      "-\n",
      "Saving full model to checkpoints\\seq2seq_epoch_56.h5\n",
      "Main Epoch 57/100\n",
      "Shuffling data.\n",
      "258/258 [==============================] - 562s 2s/step - loss: 0.0754 - accuracy: 0.9789 - truncated_acc: 0.9710 - truncated_loss: 0.1036 - val_loss: 0.0763 - val_accuracy: 0.9806 - val_truncated_acc: 0.9733 - val_truncated_loss: 0.1049\n",
      "-\n",
      "Input tokens:   ['in', 'uAnder', \"'And\", \"YoKu're\", 'the']\n",
      "Decoded tokens: ['in', 'under', \"'And\", \"You're\", 'thee']\n",
      "Target tokens:  ['in', 'under', \"'And\", \"You're\", 'the']\n",
      "-\n",
      "Saving full model to checkpoints\\seq2seq_epoch_57.h5\n",
      "Main Epoch 58/100\n",
      "Shuffling data.\n",
      "258/258 [==============================] - 560s 2s/step - loss: 0.0746 - accuracy: 0.9792 - truncated_acc: 0.9714 - truncated_loss: 0.1026 - val_loss: 0.0741 - val_accuracy: 0.9813 - val_truncated_acc: 0.9743 - val_truncated_loss: 0.1019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input tokens:   ['he', 'ought', 'throgh', 'einto', 'was']\n",
      "Decoded tokens: ['he', 'ought', 'through', 'ention', 'was']\n",
      "Target tokens:  ['the', 'ought', 'through', 'into', 'was']\n",
      "-\n",
      "Saving full model to checkpoints\\seq2seq_epoch_58.h5\n",
      "Main Epoch 59/100\n",
      "Shuffling data.\n",
      "258/258 [==============================] - 557s 2s/step - loss: 0.0740 - accuracy: 0.9793 - truncated_acc: 0.9715 - truncated_loss: 0.1017 - val_loss: 0.0752 - val_accuracy: 0.9802 - val_truncated_acc: 0.9728 - val_truncated_loss: 0.1034\n",
      "-\n",
      "Input tokens:   ['if', 'ou', 'in', 'anixous', 'instead']\n",
      "Decoded tokens: ['if', 'ou', 'in', 'anxious', 'instead']\n",
      "Target tokens:  ['if', 'you', 'in', 'anxious', 'instead']\n",
      "-\n",
      "Saving full model to checkpoints\\seq2seq_epoch_59.h5\n",
      "Main Epoch 60/100\n",
      "Shuffling data.\n",
      "258/258 [==============================] - 557s 2s/step - loss: 0.0738 - accuracy: 0.9795 - truncated_acc: 0.9718 - truncated_loss: 0.1014 - val_loss: 0.0727 - val_accuracy: 0.9813 - val_truncated_acc: 0.9743 - val_truncated_loss: 0.0999\n",
      "-\n",
      "Input tokens:   ['lyTng', 'a', \"'Tha's\", 'cDowd', 'abut']\n",
      "Decoded tokens: ['lying', 'a', \"'That's\", 'crow', 'abut']\n",
      "Target tokens:  ['lying', 'a', \"'That's\", 'crowd', 'about']\n",
      "-\n",
      "Saving full model to checkpoints\\seq2seq_epoch_60.h5\n",
      "Main Epoch 61/100\n",
      "Shuffling data.\n",
      "258/258 [==============================] - 560s 2s/step - loss: 0.0724 - accuracy: 0.9797 - truncated_acc: 0.9721 - truncated_loss: 0.0995 - val_loss: 0.0750 - val_accuracy: 0.9814 - val_truncated_acc: 0.9745 - val_truncated_loss: 0.1032\n",
      "-\n",
      "Input tokens:   ['Seen', 'jury', 'hid', 'it', 'boor']\n",
      "Decoded tokens: ['Seen', 'jury', 'hid', 'it', 'boor']\n",
      "Target tokens:  ['been', 'jury', 'had', 'it', 'door']\n",
      "-\n",
      "Saving full model to checkpoints\\seq2seq_epoch_61.h5\n",
      "Main Epoch 62/100\n",
      "Shuffling data.\n",
      "258/258 [==============================] - 558s 2s/step - loss: 0.0717 - accuracy: 0.9799 - truncated_acc: 0.9724 - truncated_loss: 0.0985 - val_loss: 0.0714 - val_accuracy: 0.9818 - val_truncated_acc: 0.9750 - val_truncated_loss: 0.0982\n",
      "-\n",
      "Input tokens:   ['Alice', 'Th', 'turn', 'obttle', 'colt']\n",
      "Decoded tokens: ['Alice', 'Thy', 'turn', 'bottle', 'colt']\n",
      "Target tokens:  ['Alice', 'The', 'turn', 'bottle', 'cost']\n",
      "-\n",
      "Saving full model to checkpoints\\seq2seq_epoch_62.h5\n",
      "Main Epoch 63/100\n",
      "Shuffling data.\n",
      "258/258 [==============================] - 556s 2s/step - loss: 0.0717 - accuracy: 0.9799 - truncated_acc: 0.9724 - truncated_loss: 0.0986 - val_loss: 0.0742 - val_accuracy: 0.9808 - val_truncated_acc: 0.9735 - val_truncated_loss: 0.1020\n",
      "-\n",
      "Input tokens:   ['weBe', 'triued', 'planD', 'th', 'anC']\n",
      "Decoded tokens: ['wee', 'tried', 'plane', 'th', 'ane']\n",
      "Target tokens:  ['were', 'tried', \"plan'\", 'the', 'and']\n",
      "-\n",
      "Saving full model to checkpoints\\seq2seq_epoch_63.h5\n",
      "Main Epoch 64/100\n",
      "Shuffling data.\n",
      "258/258 [==============================] - 558s 2s/step - loss: 0.0714 - accuracy: 0.9800 - truncated_acc: 0.9724 - truncated_loss: 0.0982 - val_loss: 0.0750 - val_accuracy: 0.9808 - val_truncated_acc: 0.9735 - val_truncated_loss: 0.1032\n",
      "-\n",
      "Input tokens:   ['hte', 'hKer', 'Eminutes', 'no', \"one'\"]\n",
      "Decoded tokens: ['hate', 'her', 'Eminutes', 'no', \"one'\"]\n",
      "Target tokens:  ['the', 'her', 'minutes', 'no', \"one'\"]\n",
      "-\n",
      "Saving full model to checkpoints\\seq2seq_epoch_64.h5\n",
      "Main Epoch 65/100\n",
      "Shuffling data.\n",
      "258/258 [==============================] - 557s 2s/step - loss: 0.0698 - accuracy: 0.9805 - truncated_acc: 0.9731 - truncated_loss: 0.0960 - val_loss: 0.0721 - val_accuracy: 0.9814 - val_truncated_acc: 0.9744 - val_truncated_loss: 0.0991\n",
      "-\n",
      "Input tokens:   ['aers', 'So', 'watter', 'on', 'te']\n",
      "Decoded tokens: ['aers', 'So', 'watter', 'on', 'te']\n",
      "Target tokens:  ['ears', 'So', 'water', 'on', 'the']\n",
      "-\n",
      "Saving full model to checkpoints\\seq2seq_epoch_65.h5\n",
      "Main Epoch 66/100\n",
      "Shuffling data.\n",
      "258/258 [==============================] - 558s 2s/step - loss: 0.0687 - accuracy: 0.9807 - truncated_acc: 0.9734 - truncated_loss: 0.0945 - val_loss: 0.0761 - val_accuracy: 0.9806 - val_truncated_acc: 0.9733 - val_truncated_loss: 0.1047\n",
      "-\n",
      "Input tokens:   ['it', 'htat', 'becase', 'at', 'Xquite']\n",
      "Decoded tokens: ['it', 'hat', 'becase', 'at', 'quite']\n",
      "Target tokens:  [\"it'\", 'that', 'because', 'at', 'quite']\n",
      "-\n",
      "Saving full model to checkpoints\\seq2seq_epoch_66.h5\n",
      "Main Epoch 67/100\n",
      "Shuffling data.\n",
      "258/258 [==============================] - 573s 2s/step - loss: 0.0682 - accuracy: 0.9808 - truncated_acc: 0.9736 - truncated_loss: 0.0937 - val_loss: 0.0722 - val_accuracy: 0.9820 - val_truncated_acc: 0.9752 - val_truncated_loss: 0.0993\n",
      "-\n",
      "Input tokens:   ['as', 'By', 'to', 'HNere', 'teh']\n",
      "Decoded tokens: ['as', 'By', 'to', 'Here', 'the']\n",
      "Target tokens:  ['was', \"'By\", 'to', 'Here', 'the']\n",
      "-\n",
      "Saving full model to checkpoints\\seq2seq_epoch_67.h5\n",
      "Main Epoch 68/100\n",
      "Shuffling data.\n",
      "258/258 [==============================] - 589s 2s/step - loss: 0.0672 - accuracy: 0.9811 - truncated_acc: 0.9741 - truncated_loss: 0.0923 - val_loss: 0.0710 - val_accuracy: 0.9822 - val_truncated_acc: 0.9756 - val_truncated_loss: 0.0977\n",
      "-\n",
      "Input tokens:   ['to', 'rob', 'masten', 'sxhould', 'tat']\n",
      "Decoded tokens: ['to', 'rob', 'masten', 'should', 'tat']\n",
      "Target tokens:  ['to', 'row', 'master', 'should', 'that']\n",
      "-\n",
      "Saving full model to checkpoints\\seq2seq_epoch_68.h5\n",
      "Main Epoch 69/100\n",
      "Shuffling data.\n",
      "258/258 [==============================] - 593s 2s/step - loss: 0.0672 - accuracy: 0.9811 - truncated_acc: 0.9740 - truncated_loss: 0.0925 - val_loss: 0.0732 - val_accuracy: 0.9816 - val_truncated_acc: 0.9746 - val_truncated_loss: 0.1007\n",
      "-\n",
      "Input tokens:   ['olok', 'abomt', \"Queen's\", 'WAS', 'at']\n",
      "Decoded tokens: ['look', 'abort', \"Queen's\", 'WAS', 'at']\n",
      "Target tokens:  ['look', 'about', \"Queen's\", 'WAS', 'at']\n",
      "-\n",
      "Saving full model to checkpoints\\seq2seq_epoch_69.h5\n",
      "Main Epoch 70/100\n",
      "Shuffling data.\n",
      "258/258 [==============================] - 588s 2s/step - loss: 0.0678 - accuracy: 0.9809 - truncated_acc: 0.9737 - truncated_loss: 0.0933 - val_loss: 0.0718 - val_accuracy: 0.9814 - val_truncated_acc: 0.9744 - val_truncated_loss: 0.0987\n",
      "-\n",
      "Input tokens:   ['of', 'nmae', 'to', \"'and\", 'wya']\n",
      "Decoded tokens: ['of', 'name', 'to', \"'and\", 'way']\n",
      "Target tokens:  ['of', 'name', 'to', \"'and\", 'way']\n",
      "-\n",
      "Saving full model to checkpoints\\seq2seq_epoch_70.h5\n",
      "Main Epoch 71/100\n",
      "Shuffling data.\n",
      "258/258 [==============================] - 589s 2s/step - loss: 0.0671 - accuracy: 0.9811 - truncated_acc: 0.9741 - truncated_loss: 0.0923 - val_loss: 0.0698 - val_accuracy: 0.9825 - val_truncated_acc: 0.9760 - val_truncated_loss: 0.0959\n",
      "-\n",
      "Input tokens:   ['upstairs', 'OF', 'cas', 'in', 'shw']\n",
      "Decoded tokens: ['upstairs', 'OFF', 'cas', 'in', 'show']\n",
      "Target tokens:  ['upstairs', 'OF', 'was', 'in', 'she']\n",
      "-\n",
      "Saving full model to checkpoints\\seq2seq_epoch_71.h5\n",
      "Main Epoch 72/100\n",
      "Shuffling data.\n",
      "258/258 [==============================] - 589s 2s/step - loss: 0.0661 - accuracy: 0.9815 - truncated_acc: 0.9745 - truncated_loss: 0.0909 - val_loss: 0.0719 - val_accuracy: 0.9820 - val_truncated_acc: 0.9753 - val_truncated_loss: 0.0989\n",
      "-\n",
      "Input tokens:   [\"Ron't\", 'smiled', 'at', \"nwo'\", 'you']\n",
      "Decoded tokens: [\"Ron't\", 'smiled', 'at', \"now'\", 'you']\n",
      "Target tokens:  [\"won't\", 'smiled', 'at', \"now'\", 'you']\n",
      "-\n",
      "Saving full model to checkpoints\\seq2seq_epoch_72.h5\n",
      "Main Epoch 73/100\n",
      "Shuffling data.\n",
      "258/258 [==============================] - 590s 2s/step - loss: 0.0666 - accuracy: 0.9813 - truncated_acc: 0.9743 - truncated_loss: 0.0915 - val_loss: 0.0716 - val_accuracy: 0.9815 - val_truncated_acc: 0.9745 - val_truncated_loss: 0.0984\n",
      "-\n",
      "Input tokens:   ['Qshe', 'Swho', 'ret', 'pantrng', 'osrts']\n",
      "Decoded tokens: ['she', 'Show', 'ret', 'panting', 'sorts']\n",
      "Target tokens:  ['she', 'who', 'rest', 'panting', 'sorts']\n",
      "-\n",
      "Saving full model to checkpoints\\seq2seq_epoch_73.h5\n",
      "Main Epoch 74/100\n",
      "Shuffling data.\n",
      "258/258 [==============================] - 589s 2s/step - loss: 0.0647 - accuracy: 0.9817 - truncated_acc: 0.9748 - truncated_loss: 0.0889 - val_loss: 0.0745 - val_accuracy: 0.9809 - val_truncated_acc: 0.9737 - val_truncated_loss: 0.1024\n",
      "-\n",
      "Input tokens:   ['here', 'It', 'poor', 'AKlice', 'Ethe']\n",
      "Decoded tokens: ['here', 'It', 'poor', 'Alice', 'Ethe']\n",
      "Target tokens:  ['There', 'It', 'poor', 'Alice', 'the']\n",
      "-\n",
      "Saving full model to checkpoints\\seq2seq_epoch_74.h5\n",
      "Main Epoch 75/100\n",
      "Shuffling data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "258/258 [==============================] - 591s 2s/step - loss: 0.0630 - accuracy: 0.9823 - truncated_acc: 0.9756 - truncated_loss: 0.0866 - val_loss: 0.0731 - val_accuracy: 0.9811 - val_truncated_acc: 0.9740 - val_truncated_loss: 0.1006\n",
      "-\n",
      "Input tokens:   ['gettSng', 'ssee', 'Vhat', 'ytell', 'to']\n",
      "Decoded tokens: ['getting', 'sees', 'What', 'yell', 'to']\n",
      "Target tokens:  ['getting', 'see', 'that', 'tell', 'to']\n",
      "-\n",
      "Saving full model to checkpoints\\seq2seq_epoch_75.h5\n",
      "Main Epoch 76/100\n",
      "Shuffling data.\n",
      "258/258 [==============================] - 590s 2s/step - loss: 0.0643 - accuracy: 0.9820 - truncated_acc: 0.9752 - truncated_loss: 0.0884 - val_loss: 0.0696 - val_accuracy: 0.9817 - val_truncated_acc: 0.9748 - val_truncated_loss: 0.0957\n",
      "-\n",
      "Input tokens:   ['exactly', 'Aay', 'a', 'Mthe', 'hoem']\n",
      "Decoded tokens: ['exactly', 'Aay', 'a', 'Mothe', 'home']\n",
      "Target tokens:  ['exactly', 'way', 'a', 'the', 'home']\n",
      "-\n",
      "Saving full model to checkpoints\\seq2seq_epoch_76.h5\n",
      "Main Epoch 77/100\n",
      "Shuffling data.\n",
      "258/258 [==============================] - 591s 2s/step - loss: 0.0635 - accuracy: 0.9820 - truncated_acc: 0.9753 - truncated_loss: 0.0873 - val_loss: 0.0729 - val_accuracy: 0.9814 - val_truncated_acc: 0.9744 - val_truncated_loss: 0.1003\n",
      "-\n",
      "Input tokens:   ['itr', 'as', 'nCw', 'the', 'it']\n",
      "Decoded tokens: ['tir', 'as', 'new', 'thee', 'it']\n",
      "Target tokens:  [\"it'\", 'as', 'now', 'the', 'it']\n",
      "-\n",
      "Saving full model to checkpoints\\seq2seq_epoch_77.h5\n",
      "Main Epoch 78/100\n",
      "Shuffling data.\n",
      "258/258 [==============================] - 589s 2s/step - loss: 0.0632 - accuracy: 0.9820 - truncated_acc: 0.9752 - truncated_loss: 0.0869 - val_loss: 0.0719 - val_accuracy: 0.9812 - val_truncated_acc: 0.9741 - val_truncated_loss: 0.0988\n",
      "-\n",
      "Input tokens:   ['lookend', 'minute', 'abotu', \"'yWu\", 'hte']\n",
      "Decoded tokens: ['lookened', 'minute', 'about', \"'yeu\", 'hate']\n",
      "Target tokens:  ['looked', 'minute', 'about', \"'you\", 'the']\n",
      "-\n",
      "Saving full model to checkpoints\\seq2seq_epoch_78.h5\n",
      "Main Epoch 79/100\n",
      "Shuffling data.\n",
      "258/258 [==============================] - 588s 2s/step - loss: 0.0625 - accuracy: 0.9824 - truncated_acc: 0.9759 - truncated_loss: 0.0859 - val_loss: 0.0698 - val_accuracy: 0.9816 - val_truncated_acc: 0.9747 - val_truncated_loss: 0.0959\n",
      "-\n",
      "Input tokens:   ['nibbled', \"wawsn't\", 'it', 'I', \"faet'\"]\n",
      "Decoded tokens: ['nibbled', \"wasn't\", 'it', 'I', \"fate'\"]\n",
      "Target tokens:  ['nibbled', \"wasn't\", 'it', 'I', \"feet'\"]\n",
      "-\n",
      "Saving full model to checkpoints\\seq2seq_epoch_79.h5\n",
      "Main Epoch 80/100\n",
      "Shuffling data.\n",
      "258/258 [==============================] - 561s 2s/step - loss: 0.0620 - accuracy: 0.9827 - truncated_acc: 0.9762 - truncated_loss: 0.0853 - val_loss: 0.0692 - val_accuracy: 0.9825 - val_truncated_acc: 0.9759 - val_truncated_loss: 0.0952\n",
      "-\n",
      "Input tokens:   ['IN', \"O'ff\", 'much', 'riddlBs', 'to']\n",
      "Decoded tokens: ['IN', \"'Of\", 'much', 'riddles', 'to']\n",
      "Target tokens:  ['IN', \"'Off\", 'much', 'riddles', 'to']\n",
      "-\n",
      "Saving full model to checkpoints\\seq2seq_epoch_80.h5\n",
      "Main Epoch 81/100\n",
      "Shuffling data.\n",
      "258/258 [==============================] - 559s 2s/step - loss: 0.0625 - accuracy: 0.9824 - truncated_acc: 0.9758 - truncated_loss: 0.0859 - val_loss: 0.0703 - val_accuracy: 0.9818 - val_truncated_acc: 0.9749 - val_truncated_loss: 0.0967\n",
      "-\n",
      "Input tokens:   ['Lew s', 'no', \"Blil'\", 'Ybout', 'or']\n",
      "Decoded tokens: ['Lews', 'no', \"Bill'\", 'bout', 'or']\n",
      "Target tokens:  ['Lewis', 'no', \"Bill'\", 'about', 'or']\n",
      "-\n",
      "Saving full model to checkpoints\\seq2seq_epoch_81.h5\n",
      "Main Epoch 82/100\n",
      "Shuffling data.\n",
      "258/258 [==============================] - 560s 2s/step - loss: 0.0611 - accuracy: 0.9828 - truncated_acc: 0.9763 - truncated_loss: 0.0840 - val_loss: 0.0728 - val_accuracy: 0.9815 - val_truncated_acc: 0.9746 - val_truncated_loss: 0.1001\n",
      "-\n",
      "Input tokens:   ['knowin', 'wa', 'at', 'tay', 'do']\n",
      "Decoded tokens: ['knowing', 'wa', 'at', 'tay', 'do']\n",
      "Target tokens:  ['knowing', 'was', 'at', 'stay', 'do']\n",
      "-\n",
      "Saving full model to checkpoints\\seq2seq_epoch_82.h5\n",
      "Main Epoch 83/100\n",
      "Shuffling data.\n",
      "258/258 [==============================] - 558s 2s/step - loss: 0.0615 - accuracy: 0.9826 - truncated_acc: 0.9761 - truncated_loss: 0.0846 - val_loss: 0.0687 - val_accuracy: 0.9821 - val_truncated_acc: 0.9754 - val_truncated_loss: 0.0944\n",
      "-\n",
      "Input tokens:   [\"'I\", 'hdead', 'lesion', 'porpose', 'aHtter']\n",
      "Decoded tokens: [\"'I\", 'head', 'lesion', 'propose', 'Hatter']\n",
      "Target tokens:  [\"'I\", 'head', 'lesson', 'porpoise', 'Hatter']\n",
      "-\n",
      "Saving full model to checkpoints\\seq2seq_epoch_83.h5\n",
      "Main Epoch 84/100\n",
      "Shuffling data.\n",
      "258/258 [==============================] - 559s 2s/step - loss: 0.0614 - accuracy: 0.9827 - truncated_acc: 0.9763 - truncated_loss: 0.0844 - val_loss: 0.0698 - val_accuracy: 0.9820 - val_truncated_acc: 0.9753 - val_truncated_loss: 0.0960\n",
      "-\n",
      "Input tokens:   ['anotheZ', 'thsi', 'contined', 'Kuppose', 'Vome']\n",
      "Decoded tokens: ['another', 'this', 'contined', 'suppose', 'come']\n",
      "Target tokens:  ['another', 'this', 'continued', 'suppose', 'some']\n",
      "-\n",
      "Saving full model to checkpoints\\seq2seq_epoch_84.h5\n",
      "Main Epoch 85/100\n",
      "Shuffling data.\n",
      "258/258 [==============================] - 560s 2s/step - loss: 0.0613 - accuracy: 0.9826 - truncated_acc: 0.9761 - truncated_loss: 0.0843 - val_loss: 0.0716 - val_accuracy: 0.9810 - val_truncated_acc: 0.9738 - val_truncated_loss: 0.0984\n",
      "-\n",
      "Input tokens:   ['some', 'feBet', 'Dormopuse', 'hrad', \"youwrself'\"]\n",
      "Decoded tokens: ['some', 'feet', 'Doromose', 'hard', \"yourself'\"]\n",
      "Target tokens:  ['some', 'feet', 'Dormouse', 'hard', \"yourself'\"]\n",
      "-\n",
      "Saving full model to checkpoints\\seq2seq_epoch_85.h5\n",
      "Main Epoch 86/100\n",
      "Shuffling data.\n",
      "258/258 [==============================] - 565s 2s/step - loss: 0.0601 - accuracy: 0.9830 - truncated_acc: 0.9766 - truncated_loss: 0.0826 - val_loss: 0.0715 - val_accuracy: 0.9816 - val_truncated_acc: 0.9747 - val_truncated_loss: 0.0983\n",
      "-\n",
      "Input tokens:   ['to', 'it', 'after', 'th', 'thought']\n",
      "Decoded tokens: ['to', 'it', 'after', 'th', 'thought']\n",
      "Target tokens:  ['to', 'it', 'after', 'the', 'thought']\n",
      "-\n",
      "Saving full model to checkpoints\\seq2seq_epoch_86.h5\n",
      "Main Epoch 87/100\n",
      "Shuffling data.\n",
      "258/258 [==============================] - 562s 2s/step - loss: 0.0597 - accuracy: 0.9831 - truncated_acc: 0.9768 - truncated_loss: 0.0821 - val_loss: 0.0721 - val_accuracy: 0.9822 - val_truncated_acc: 0.9755 - val_truncated_loss: 0.0991\n",
      "-\n",
      "Input tokens:   ['tUhe', 'Like', 'sya', 'thPe', 'as']\n",
      "Decoded tokens: ['the', 'Like', 'say', 'the', 'as']\n",
      "Target tokens:  ['the', 'Like', 'say', 'the', 'as']\n",
      "-\n",
      "Saving full model to checkpoints\\seq2seq_epoch_87.h5\n",
      "Main Epoch 88/100\n",
      "Shuffling data.\n",
      "258/258 [==============================] - 565s 2s/step - loss: 0.0594 - accuracy: 0.9831 - truncated_acc: 0.9767 - truncated_loss: 0.0816 - val_loss: 0.0689 - val_accuracy: 0.9821 - val_truncated_acc: 0.9754 - val_truncated_loss: 0.0947\n",
      "-\n",
      "Input tokens:   ['UAnd', 'spKell', 'fro', 'Hwo', 'the']\n",
      "Decoded tokens: ['Und', 'spell', 'from', 'How', 'thee']\n",
      "Target tokens:  [\"'And\", 'spell', 'for', 'How', 'the']\n",
      "-\n",
      "Saving full model to checkpoints\\seq2seq_epoch_88.h5\n",
      "Main Epoch 89/100\n",
      "Shuffling data.\n",
      "258/258 [==============================] - 565s 2s/step - loss: 0.0593 - accuracy: 0.9830 - truncated_acc: 0.9766 - truncated_loss: 0.0816 - val_loss: 0.0699 - val_accuracy: 0.9822 - val_truncated_acc: 0.9756 - val_truncated_loss: 0.0961\n",
      "-\n",
      "Input tokens:   ['I', 'as', 'sacys', 'my', \"unimportant'\"]\n",
      "Decoded tokens: ['I', 'as', 'says', 'my', \"unimportant's\"]\n",
      "Target tokens:  ['I', 'as', 'says', 'my', \"'unimportant'\"]\n",
      "-\n",
      "Saving full model to checkpoints\\seq2seq_epoch_89.h5\n",
      "Main Epoch 90/100\n",
      "Shuffling data.\n",
      "258/258 [==============================] - 564s 2s/step - loss: 0.0583 - accuracy: 0.9834 - truncated_acc: 0.9771 - truncated_loss: 0.0801 - val_loss: 0.0699 - val_accuracy: 0.9820 - val_truncated_acc: 0.9753 - val_truncated_loss: 0.0961\n",
      "-\n",
      "Input tokens:   ['nowhere', 'is', 'to', 'not', 'at']\n",
      "Decoded tokens: ['nowhere', 'is', 'to', 'not', 'at']\n",
      "Target tokens:  ['nowhere', 'is', 'to', 'not', 'at']\n",
      "-\n",
      "Saving full model to checkpoints\\seq2seq_epoch_90.h5\n",
      "Main Epoch 91/100\n",
      "Shuffling data.\n",
      "258/258 [==============================] - 564s 2s/step - loss: 0.0586 - accuracy: 0.9834 - truncated_acc: 0.9771 - truncated_loss: 0.0806 - val_loss: 0.0696 - val_accuracy: 0.9819 - val_truncated_acc: 0.9751 - val_truncated_loss: 0.0958\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input tokens:   ['Peat', 'hVm', 'in', 'my', 'it']\n",
      "Decoded tokens: ['Peat', 'him', 'in', 'my', 'it']\n",
      "Target tokens:  ['beat', 'him', 'in', 'my', 'it']\n",
      "-\n",
      "Saving full model to checkpoints\\seq2seq_epoch_91.h5\n",
      "Main Epoch 92/100\n",
      "Shuffling data.\n",
      "258/258 [==============================] - 565s 2s/step - loss: 0.0583 - accuracy: 0.9834 - truncated_acc: 0.9771 - truncated_loss: 0.0801 - val_loss: 0.0704 - val_accuracy: 0.9818 - val_truncated_acc: 0.9750 - val_truncated_loss: 0.0968\n",
      "-\n",
      "Input tokens:   ['th', 'well', 'Turtle', 'sHt', 'in']\n",
      "Decoded tokens: ['th', 'well', 'Turtle', 'set', 'in']\n",
      "Target tokens:  ['the', 'well', 'Turtle', 'set', 'in']\n",
      "-\n",
      "Saving full model to checkpoints\\seq2seq_epoch_92.h5\n",
      "Main Epoch 93/100\n",
      "Shuffling data.\n",
      "258/258 [==============================] - 568s 2s/step - loss: 0.0574 - accuracy: 0.9837 - truncated_acc: 0.9775 - truncated_loss: 0.0789 - val_loss: 0.0716 - val_accuracy: 0.9818 - val_truncated_acc: 0.9749 - val_truncated_loss: 0.0985\n",
      "-\n",
      "Input tokens:   ['fit', 'ought', 'if', 'yuo', 'szid']\n",
      "Decoded tokens: ['fit', 'ought', 'if', 'you', 'sized']\n",
      "Target tokens:  ['fit', 'ought', 'if', 'you', 'said']\n",
      "-\n",
      "Saving full model to checkpoints\\seq2seq_epoch_93.h5\n",
      "Main Epoch 94/100\n",
      "Shuffling data.\n",
      "258/258 [==============================] - 565s 2s/step - loss: 0.0571 - accuracy: 0.9838 - truncated_acc: 0.9777 - truncated_loss: 0.0785 - val_loss: 0.0691 - val_accuracy: 0.9828 - val_truncated_acc: 0.9764 - val_truncated_loss: 0.0949\n",
      "-\n",
      "Input tokens:   ['thY', 'were', 'went', 'anwser', 'a']\n",
      "Decoded tokens: ['thy', 'were', 'went', 'answer', 'a']\n",
      "Target tokens:  ['the', 'were', 'went', 'answer', 'a']\n",
      "-\n",
      "Saving full model to checkpoints\\seq2seq_epoch_94.h5\n",
      "Main Epoch 95/100\n",
      "Shuffling data.\n",
      "258/258 [==============================] - 567s 2s/step - loss: 0.0562 - accuracy: 0.9841 - truncated_acc: 0.9781 - truncated_loss: 0.0773 - val_loss: 0.0696 - val_accuracy: 0.9822 - val_truncated_acc: 0.9755 - val_truncated_loss: 0.0956\n",
      "-\n",
      "Input tokens:   ['remarked', 'wh o', 'on', 'lengtrh', 'seems']\n",
      "Decoded tokens: ['remarked', 'who', 'on', 'length', 'seems']\n",
      "Target tokens:  ['remarked', 'who', 'on', 'length', 'seems']\n",
      "-\n",
      "Saving full model to checkpoints\\seq2seq_epoch_95.h5\n",
      "Main Epoch 96/100\n",
      "Shuffling data.\n",
      "258/258 [==============================] - 582s 2s/step - loss: 0.0576 - accuracy: 0.9836 - truncated_acc: 0.9774 - truncated_loss: 0.0792 - val_loss: 0.0687 - val_accuracy: 0.9823 - val_truncated_acc: 0.9756 - val_truncated_loss: 0.0944\n",
      "-\n",
      "Input tokens:   [\"Ht's\", \"tongue'\", 'hansdome', 'do', 'sittfng']\n",
      "Decoded tokens: [\"Het's\", \"tongue'\", 'handsome', 'do', 'sitting']\n",
      "Target tokens:  [\"it's\", \"tongue'\", 'handsome', 'do', 'sitting']\n",
      "-\n",
      "Saving full model to checkpoints\\seq2seq_epoch_96.h5\n",
      "Main Epoch 97/100\n",
      "Shuffling data.\n",
      "258/258 [==============================] - 634s 2s/step - loss: 0.0562 - accuracy: 0.9839 - truncated_acc: 0.9779 - truncated_loss: 0.0772 - val_loss: 0.0679 - val_accuracy: 0.9828 - val_truncated_acc: 0.9763 - val_truncated_loss: 0.0934\n",
      "-\n",
      "Input tokens:   ['aer', 'a', \"donX't\", 'nto', 'to']\n",
      "Decoded tokens: ['ear', 'a', \"don't\", 'not', 'to']\n",
      "Target tokens:  ['are', 'a', \"don't\", 'not', 'to']\n",
      "-\n",
      "Saving full model to checkpoints\\seq2seq_epoch_97.h5\n",
      "Main Epoch 98/100\n",
      "Shuffling data.\n",
      "258/258 [==============================] - 621s 2s/step - loss: 0.0560 - accuracy: 0.9840 - truncated_acc: 0.9780 - truncated_loss: 0.0769 - val_loss: 0.0661 - val_accuracy: 0.9832 - val_truncated_acc: 0.9768 - val_truncated_loss: 0.0908\n",
      "-\n",
      "Input tokens:   ['yo', 'hnly', \"yot're\", \"Dina'll\", \"'Onr\"]\n",
      "Decoded tokens: ['you', 'hinly', \"yo'te\", \"Dian'll\", \"'On\"]\n",
      "Target tokens:  ['you', 'only', \"you're\", \"Dinah'll\", \"'Or\"]\n",
      "-\n",
      "Saving full model to checkpoints\\seq2seq_epoch_98.h5\n",
      "Main Epoch 99/100\n",
      "Shuffling data.\n",
      "258/258 [==============================] - 648s 3s/step - loss: 0.0556 - accuracy: 0.9843 - truncated_acc: 0.9784 - truncated_loss: 0.0764 - val_loss: 0.0693 - val_accuracy: 0.9820 - val_truncated_acc: 0.9753 - val_truncated_loss: 0.0953\n",
      "-\n",
      "Input tokens:   ['sbid', 'fater', 'I', \"ell'\", 'bketween']\n",
      "Decoded tokens: ['bid', 'fatter', 'I', \"bell'\", 'between']\n",
      "Target tokens:  ['said', 'after', 'I', \"well'\", 'between']\n",
      "-\n",
      "Saving full model to checkpoints\\seq2seq_epoch_99.h5\n",
      "Main Epoch 100/100\n",
      "Shuffling data.\n",
      "258/258 [==============================] - 632s 2s/step - loss: 0.0554 - accuracy: 0.9842 - truncated_acc: 0.9783 - truncated_loss: 0.0761 - val_loss: 0.0682 - val_accuracy: 0.9829 - val_truncated_acc: 0.9765 - val_truncated_loss: 0.0938\n",
      "-\n",
      "Input tokens:   ['she', 'thvnk', 'BUSu', 'only', \"i n't\"]\n",
      "Decoded tokens: ['she', 'think', 'BBU', 'only', \"in't\"]\n",
      "Target tokens:  ['she', 'think', 'BUSY', 'only', \"isn't\"]\n",
      "-\n",
      "Saving full model to checkpoints\\seq2seq_epoch_100.h5\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import import_ipynb\n",
    "import Project\n",
    "np.random.seed(1234)\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "from utils import CharacterTable, transform\n",
    "from utils import batch, datagen, decode_sequences\n",
    "from utils import read_text, tokenize\n",
    "from model import seq2seq\n",
    "error_rate = 0.8\n",
    "hidden_size = 512\n",
    "nb_epochs = 100\n",
    "train_batch_size = 128\n",
    "val_batch_size = 256\n",
    "sample_mode = 'argmax'\n",
    "reverse = True\n",
    "data_path = r'C:\\Users\\ganes\\Music\\data'\n",
    "train_books = ['nietzsche.txt', 'pride_and_prejudice.txt',\n",
    "               'shakespeare.txt', 'war_and_peace.txt']\n",
    "val_books = ['wonderland.txt']\n",
    "if __name__ == '__main__':\n",
    "    # Prepare training data.\n",
    "    text  = read_text(data_path, train_books)\n",
    "    vocab = tokenize(text)\n",
    "    vocab = list(filter(None, set(vocab)))\n",
    "    maxlen = max([len(token) for token in vocab]) + 2\n",
    "    train_encoder, train_decoder, train_target = transform(\n",
    "        vocab, maxlen, error_rate=error_rate, shuffle=False)\n",
    "    print(train_encoder[:10])\n",
    "    print(train_decoder[:10])\n",
    "    print(train_target[:10])\n",
    "\n",
    "    input_chars = set(' '.join(train_encoder))\n",
    "    target_chars = set(' '.join(train_decoder))\n",
    "    nb_input_chars = len(input_chars)\n",
    "    nb_target_chars = len(target_chars)\n",
    "\n",
    "    print('Size of training vocabulary =', len(vocab))\n",
    "    print('Number of unique input characters:', nb_input_chars)\n",
    "    print('Number of unique target characters:', nb_target_chars)\n",
    "    print('Max sequence length in the training set:', maxlen)\n",
    "\n",
    "    # Prepare validation data.\n",
    "    text = read_text(data_path, val_books)\n",
    "    val_tokens = tokenize(text)\n",
    "    val_tokens = list(filter(None, val_tokens))\n",
    "\n",
    "    val_maxlen = max([len(token) for token in val_tokens]) + 2\n",
    "    val_encoder, val_decoder, val_target = transform(\n",
    "        val_tokens, maxlen, error_rate=error_rate, shuffle=False)\n",
    "    print(val_encoder[:10])\n",
    "    print(val_decoder[:10])\n",
    "    print(val_target[:10])\n",
    "    print('Number of non-unique validation tokens =', len(val_tokens))\n",
    "    print('Max sequence length in the validation set:', val_maxlen)\n",
    "\n",
    "    # Define training and evaluation configuration.\n",
    "    input_ctable  = CharacterTable(input_chars)\n",
    "    target_ctable = CharacterTable(target_chars)\n",
    "\n",
    "    train_steps = len(vocab) // train_batch_size\n",
    "    val_steps = len(val_tokens) // val_batch_size\n",
    "\n",
    "    # Compile the model.\n",
    "    model, encoder_model, decoder_model = seq2seq(\n",
    "        hidden_size, nb_input_chars, nb_target_chars)\n",
    "    print(model.summary())\n",
    "\n",
    "    # Train and evaluate.\n",
    "    for epoch in range(nb_epochs):\n",
    "        print('Main Epoch {:d}/{:d}'.format(epoch + 1, nb_epochs))\n",
    "    \n",
    "        train_encoder, train_decoder, train_target = transform(\n",
    "            vocab, maxlen, error_rate=error_rate, shuffle=True)\n",
    "        \n",
    "        train_encoder_batch = batch(train_encoder, maxlen, input_ctable,\n",
    "                                    train_batch_size, reverse)\n",
    "        train_decoder_batch = batch(train_decoder, maxlen, target_ctable,\n",
    "                                    train_batch_size)\n",
    "        train_target_batch  = batch(train_target, maxlen, target_ctable,\n",
    "                                    train_batch_size)    \n",
    "\n",
    "        val_encoder_batch = batch(val_encoder, maxlen, input_ctable,\n",
    "                                  val_batch_size, reverse)\n",
    "        val_decoder_batch = batch(val_decoder, maxlen, target_ctable,\n",
    "                                  val_batch_size)\n",
    "        val_target_batch  = batch(val_target, maxlen, target_ctable,\n",
    "                                  val_batch_size)\n",
    "    \n",
    "        train_loader = datagen(train_encoder_batch,\n",
    "                               train_decoder_batch, train_target_batch)\n",
    "        val_loader = datagen(val_encoder_batch,\n",
    "                             val_decoder_batch, val_target_batch)\n",
    "    \n",
    "        model.fit(train_loader,steps_per_epoch=train_steps,epochs=1, verbose=1,validation_data=val_loader,validation_steps=val_steps)\n",
    "        # On epoch end - decode a batch of misspelled tokens from the validation set to visualize speller performance.\n",
    "        nb_tokens = 5\n",
    "        input_tokens, target_tokens, decoded_tokens = decode_sequences(\n",
    "            val_encoder, val_target, input_ctable, target_ctable,\n",
    "            maxlen, reverse, encoder_model, decoder_model, nb_tokens,\n",
    "            sample_mode=sample_mode, random=True)\n",
    "        \n",
    "        print('-')\n",
    "        print('Input tokens:  ', input_tokens)\n",
    "        print('Decoded tokens:', decoded_tokens)\n",
    "        print('Target tokens: ', target_tokens)\n",
    "        print('-')\n",
    "        \n",
    "        # Save the model at end of each epoch.\n",
    "        model_file = '_'.join(['seq2seq', 'epoch', str(epoch + 1)]) + '.h5'\n",
    "        save_dir = 'checkpoints'\n",
    "        if not os.path.exists(save_dir):\n",
    "            os.makedirs(save_dir)\n",
    "            \n",
    "        save_path = os.path.join(save_dir, model_file)\n",
    "        print('Saving full model to {:s}'.format(save_path))\n",
    "        model.save(save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

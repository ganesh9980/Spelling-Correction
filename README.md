# Spelling-Correction
Grammatical error correction is a process of identifying the grammatical errors and modifying them. It helps to correct errors with a high degree of accuracy and speed, and also helps to improve written English. In Natural Language Processing (NLP) applications, information normalization is significant in light of the fact that it can improve the presentation and the accuracy of NLP applications. By performing spell checking before other normalization task for different NLP applications, for example, data recovery, machine translation, text order, and opinion mining, spell looking at can lessen out  of vocabulary (OOV), decrease the size of sack of words portrayal, and produce better stemming or lemmatization result. For people, spell checking can help at the point when they are composing writings that must contain no mistakes (frequently messages in formal setting) or for a superior intelligibility of messages. Our fundamental concentration in this project is building the LSTM (Long Short-Term Memory) model for the assignment of error rectification. Specifically , we explore sequence to sequence and attention based models which have as of late demonstrated a better than the best in a class of numerous language handling problems. In this task , we are especially intrigued by Encoder-Decoder models. The fundamental thought of the model is moderately basic. We utilise two LSTM models, the first encodes the data of the possibly incorrect input text, as a vector of real-valued numbers, while the subsequent model decodes this data into the objective sentence which is the corrected prediction for the input text. 

We have used eBooks for our dataset.The eBooks were take from an online library called Project Guternberg.we have trained the model for 100 epochs and got an accuracy of 98.42%(training) and the testing accuracy was 98.29%. 
